---
title: 为什么让机器看见事物很难
date: 2021-9-12 10:39:13
tags:
 - 视觉
 - 概述
---

对于人类来说，看见周围的事物似乎是非常简单的事情。
比如我能够轻松的看见眼前的笔的轮廓，笔尖的形状，墨水随着笔尖的移动流畅地出现在纸面上，呈现出一个个的汉字。
我能清晰地看见手掌上错综复杂的纹路杂乱无章的交错着。
如果我面前出现一个从来没见过的东西，我也能很轻松的看到他的形状，色泽，纹理等等，虽然我们不知道它具体是什么东西，有什么用。
这一切对于我来说是那么自然和轻而易举，根本不需要任何思考和努力。
<!--more -->

可是当我回顾自己是怎么做到从一帧一帧的图片中看见事物时，却发现无法获得任何有用的信息。
很显然我们的大脑做过大量的计算，但并没有将这些行为和信息暴露给上层的思考相关的“进程”。
这说明大脑的功能至少可以分为两层，通过某种接口层交互。
在接口层之下，一切都是自动的，可以使用大量我们自己都不理解的技术。
在接口层之上，则是我们意识到的各种信息，可以回顾，假设，推理，纠正错误等等。
对于接口层来说，则需要其提供的信息是可验证的（至少大部分时候）。
也就是说，我虽然不知道底层是怎么样做到的，但我能验证底层给的信息是有效的。
比如，我虽然不知道底层怎么快速找出来我眼前的笔的影像的，但是我能够验证这个判断是对的。
曲线就是笔的轮廓，曲线内部的蓝色像素是笔的颜色，外部是其他纸，墨水，手产生的像素。
如果我移动手，手和笔都会移动，而本子不会移动。

视觉底层带来的好处是高效，快速.
缺点也比较明显，出现错误或歧义时很难甚至无法给它反馈和纠正错误。
比如下面这个动画中的三个齿轮，但看上去一直在转，实际上除了背景和齿轮边缘的亮度在变化之外，其他部位都没有动。
即使已经知道了这些齿轮是静止的，我们好像都无法反馈给底层。
我们的大脑还是不断告诉我们齿轮在动。
![](/images/three_gears_illusion.gif)

当然有时候我们也能给底层一些反馈，比如预设的假设或偏见。
我们来看看下面这张图动画，它分为三个部分。
中间的部分是一个旋转的舞者的投影，无论顺时钟，逆时钟或者来回摆动都能产生这个投影。
如果你盯着左边和中间部分，你会觉得中间的舞者的旋转方向和左边的一致。
如果你盯着右边和中间部分，逆有会觉得中间的舞者动旋转方向和右边一致。
![](/images/rotating_dancer_illusion.gif)

正是因为底层这个黑盒的存在，使得我们很难的直接模仿（山寨）人脑来让机器人看见事物。
尤其是想直接从像素矩阵映射到物品类别或实例时，涉及到跨好几个域的映射关系，就更加困难了。
反过来想，底层黑盒的存在又让机器人的设计相对简单一些。
因为我们可以使用任何技术来实现这个底层，而不用担心机器人自己不理解这些底层。
比如利用已知的光学，数学知识，整体部分关系甚至使用深度学习来构建这个底层。
当然接口层的设计非常关键，这决定了机器人能够有意识的应用的最底层的特征集。
